{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gyUFUrCXdlIBz9DYItH9YN3gQ2DvUMsI","timestamp":1763012969949},{"file_id":"1y83F0-UhOG-Hr1z9SL_foKF7bWhlwNdN","timestamp":1761350280938},{"file_id":"1QLWrwMANAAUc-gouHwYqluLa9CKBsDFc","timestamp":1759779956703}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# How to run on GPU\n","\n","## Step 1: Generate GitHub Access Token\n","Go to https://github.com/settings/tokens and create a personal access token with permissions to read your private repositories.\n","\n","## Step 2: Set Up Colab Environment\n","1. Clone this Colab notebook\n","2. Change the runtime type to GPU:\n","   - Navigate to **Runtime → Change runtime type**\n","   - Select **GPU** (e.g T4) as the hardware accelerator\n","   - Click **Save**\n","\n","## Step 3: Install Python 3.11\n","Install Python 3.11 to ensure compatibility with the required dependencies.\n","\n","## Step 4: Clone and Install Dependencies\n","1. Clone your repository using the GitHub token\n","\n","## Step 5: Run Training\n","Execute the command-line training script to begin model training on the GPU."],"metadata":{"id":"z4pWhxZCyMQ-"}},{"cell_type":"markdown","source":["# Install python 3.11\n","Run the cell below without editing it."],"metadata":{"id":"BTzMYZB5yynZ"}},{"cell_type":"code","source":["!sudo apt-get update -y\n","!sudo apt-get install python3.11\n","!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n","!python3.11 get-pip.py"],"metadata":{"collapsed":true,"id":"7MDWvqqxVvon","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763415810593,"user_tz":300,"elapsed":28628,"user":{"displayName":"Ying Yu Chen","userId":"03623175098010197464"}},"outputId":"2d13f99a-06b3-4f69-e0a3-08cd5282e7fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 0 B/3,\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 0 B/3,\r                                                                               \rGet:3 https://cli.github.com/packages stable InRelease [3,917 B]\n","\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 0 B/3,\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 3,632 \r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to r2u.s\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,145 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:11 https://cli.github.com/packages stable/main amd64 Packages [343 B]\n","Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,828 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,458 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,864 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,532 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,188 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n","Fetched 36.0 MB in 5s (6,624 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libpython3.11-minimal libpython3.11-stdlib python3.11-minimal\n","Suggested packages:\n","  python3.11-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.11-minimal libpython3.11-stdlib python3.11 python3.11-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 50 not upgraded.\n","Need to get 5,266 kB of archives.\n","After this operation, 21.1 MB of additional disk space will be used.\n","Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-minimal amd64 3.11.14-1+jammy1 [887 kB]\n","Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-minimal amd64 3.11.14-1+jammy1 [2,358 kB]\n","Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-stdlib amd64 3.11.14-1+jammy1 [1,927 kB]\n","Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11 amd64 3.11.14-1+jammy1 [94.3 kB]\n","Fetched 5,266 kB in 10s (542 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.11-minimal:amd64.\n","(Reading database ... 121703 files and directories currently installed.)\n","Preparing to unpack .../libpython3.11-minimal_3.11.14-1+jammy1_amd64.deb ...\n","Unpacking libpython3.11-minimal:amd64 (3.11.14-1+jammy1) ...\n","Selecting previously unselected package python3.11-minimal.\n","Preparing to unpack .../python3.11-minimal_3.11.14-1+jammy1_amd64.deb ...\n","Unpacking python3.11-minimal (3.11.14-1+jammy1) ...\n","Selecting previously unselected package libpython3.11-stdlib:amd64.\n","Preparing to unpack .../libpython3.11-stdlib_3.11.14-1+jammy1_amd64.deb ...\n","Unpacking libpython3.11-stdlib:amd64 (3.11.14-1+jammy1) ...\n","Selecting previously unselected package python3.11.\n","Preparing to unpack .../python3.11_3.11.14-1+jammy1_amd64.deb ...\n","Unpacking python3.11 (3.11.14-1+jammy1) ...\n","Setting up libpython3.11-minimal:amd64 (3.11.14-1+jammy1) ...\n","Setting up python3.11-minimal (3.11.14-1+jammy1) ...\n","Setting up libpython3.11-stdlib:amd64 (3.11.14-1+jammy1) ...\n","Setting up python3.11 (3.11.14-1+jammy1) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 2131k  100 2131k    0     0  7056k      0 --:--:-- --:--:-- --:--:-- 7057k\n","Collecting pip\n","  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n","Collecting setuptools\n","  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting wheel\n","  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n","Installing collected packages: wheel, setuptools, pip\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n","\u001b[1A\u001b[2KSuccessfully installed pip-25.3 setuptools-80.9.0 wheel-0.45.1\n"]}]},{"cell_type":"markdown","source":["# Clone and install your code\n","First we need to set some environment variables. Get your github API token and MLE repo username and put them into the below variables."],"metadata":{"id":"guhMlPoey3zE"}},{"cell_type":"code","source":["%env TOKEN=token here\n","%env USER=user name here"],"metadata":{"id":"wmmAQK12zJJP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the below code. Editing should not be necessary."],"metadata":{"id":"-JZt2xZwzS2b"}},{"cell_type":"code","source":["TOKEN = %env TOKEN\n","USER = %env USER\n","%env DIR=module-3-$USER\n","DIR = %env DIR\n","\n","!echo https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n","\n","!git clone -b master --single-branch https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n","!cd $DIR; python3.11 -m pip install -e \". [cuda]\""],"metadata":{"id":"9g7k1PPwEI75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you update your code, you can re-pull the repo by running this cell."],"metadata":{"id":"WVTsfoOBroo8"}},{"cell_type":"code","source":["!cd $DIR; git pull origin master; pip3.11 install --force-reinstall --no-cache-dir ."],"metadata":{"id":"GywpmTnozf26","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763415855734,"user_tz":300,"elapsed":16007,"user":{"displayName":"Ying Yu Chen","userId":"03623175098010197464"}},"outputId":"e046a63a-3b57-4d8c-81bd-674c0d023ba1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/Cornell-Tech-ML/module-3-chenyingyu-main\n"," * branch            master     -> FETCH_HEAD\n","Already up to date.\n","Processing /content/module-3-chenyingyu-main\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting colorama==0.4.6 (from minitorch==0.5)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Collecting hypothesis==6.138.2 (from minitorch==0.5)\n","  Downloading hypothesis-6.138.2-py3-none-any.whl.metadata (5.6 kB)\n","Collecting numba>=0.61.2 (from minitorch==0.5)\n","  Downloading numba-0.62.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n","Collecting numpy<2.0 (from minitorch==0.5)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Collecting pytest-env==1.1.5 (from minitorch==0.5)\n","  Downloading pytest_env-1.1.5-py3-none-any.whl.metadata (5.2 kB)\n","Collecting pytest==8.4.1 (from minitorch==0.5)\n","  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\n","Collecting typing-extensions (from minitorch==0.5)\n","  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting attrs>=22.2.0 (from hypothesis==6.138.2->minitorch==0.5)\n","  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n","Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis==6.138.2->minitorch==0.5)\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n","Collecting iniconfig>=1 (from pytest==8.4.1->minitorch==0.5)\n","  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting packaging>=20 (from pytest==8.4.1->minitorch==0.5)\n","  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting pluggy<2,>=1.5 (from pytest==8.4.1->minitorch==0.5)\n","  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n","Collecting pygments>=2.7.2 (from pytest==8.4.1->minitorch==0.5)\n","  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n","Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.61.2->minitorch==0.5)\n","  Downloading llvmlite-0.45.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading hypothesis-6.138.2-py3-none-any.whl (530 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.0/530.0 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytest-8.4.1-py3-none-any.whl (365 kB)\n","Downloading pytest_env-1.1.5-py3-none-any.whl (6.1 kB)\n","Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m248.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n","Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n","Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n","Downloading numba-0.62.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m172.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading llvmlite-0.45.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m246.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n","Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m692.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n","Building wheels for collected packages: minitorch\n","  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for minitorch: filename=minitorch-0.5-py3-none-any.whl size=37056 sha256=4e5d6c9bff2b31961380261225d15cf162f3388c15349da597aabd6d2a301fc9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0lyzh6th/wheels/7d/2c/7b/f9dacbc643407f64eac8bf8e9926bb96f30c2980943bb3afac\n","Successfully built minitorch\n","Installing collected packages: sortedcontainers, typing-extensions, pygments, pluggy, packaging, numpy, llvmlite, iniconfig, colorama, attrs, pytest, numba, hypothesis, pytest-env, minitorch\n","\u001b[2K  Attempting uninstall: sortedcontainers\n","\u001b[2K    Found existing installation: sortedcontainers 2.4.0\n","\u001b[2K    Uninstalling sortedcontainers-2.4.0:\n","\u001b[2K      Successfully uninstalled sortedcontainers-2.4.0\n","\u001b[2K  Attempting uninstall: typing-extensions\n","\u001b[2K    Found existing installation: typing_extensions 4.15.0\n","\u001b[2K    Uninstalling typing_extensions-4.15.0:\n","\u001b[2K      Successfully uninstalled typing_extensions-4.15.0\n","\u001b[2K  Attempting uninstall: pygments\n","\u001b[2K    Found existing installation: Pygments 2.19.2\n","\u001b[2K    Uninstalling Pygments-2.19.2:\n","\u001b[2K      Successfully uninstalled Pygments-2.19.2\n","\u001b[2K  Attempting uninstall: pluggy\n","\u001b[2K    Found existing installation: pluggy 1.6.0\n","\u001b[2K    Uninstalling pluggy-1.6.0:\n","\u001b[2K      Successfully uninstalled pluggy-1.6.0\n","\u001b[2K  Attempting uninstall: packaging\n","\u001b[2K    Found existing installation: packaging 25.0\n","\u001b[2K    Uninstalling packaging-25.0:\n","\u001b[2K      Successfully uninstalled packaging-25.0\n","\u001b[2K  Attempting uninstall: numpy\n","\u001b[2K    Found existing installation: numpy 1.26.4\n","\u001b[2K    Uninstalling numpy-1.26.4:\n","\u001b[2K      Successfully uninstalled numpy-1.26.4\n","\u001b[2K  Attempting uninstall: llvmlite\n","\u001b[2K    Found existing installation: llvmlite 0.45.1\n","\u001b[2K    Uninstalling llvmlite-0.45.1:\n","\u001b[2K      Successfully uninstalled llvmlite-0.45.1\n","\u001b[2K  Attempting uninstall: iniconfig\n","\u001b[2K    Found existing installation: iniconfig 2.3.0\n","\u001b[2K    Uninstalling iniconfig-2.3.0:\n","\u001b[2K      Successfully uninstalled iniconfig-2.3.0\n","\u001b[2K  Attempting uninstall: colorama\n","\u001b[2K    Found existing installation: colorama 0.4.6\n","\u001b[2K    Uninstalling colorama-0.4.6:\n","\u001b[2K      Successfully uninstalled colorama-0.4.6\n","\u001b[2K  Attempting uninstall: attrs\n","\u001b[2K    Found existing installation: attrs 25.4.0\n","\u001b[2K    Uninstalling attrs-25.4.0:\n","\u001b[2K      Successfully uninstalled attrs-25.4.0\n","\u001b[2K  Attempting uninstall: pytest\n","\u001b[2K    Found existing installation: pytest 8.4.1\n","\u001b[2K    Uninstalling pytest-8.4.1:\n","\u001b[2K      Successfully uninstalled pytest-8.4.1\n","\u001b[2K  Attempting uninstall: numba\n","\u001b[2K    Found existing installation: numba 0.62.1\n","\u001b[2K    Uninstalling numba-0.62.1:\n","\u001b[2K      Successfully uninstalled numba-0.62.1\n","\u001b[2K  Attempting uninstall: hypothesis\n","\u001b[2K    Found existing installation: hypothesis 6.138.2\n","\u001b[2K    Uninstalling hypothesis-6.138.2:\n","\u001b[2K      Successfully uninstalled hypothesis-6.138.2\n","\u001b[2K  Attempting uninstall: pytest-env\n","\u001b[2K    Found existing installation: pytest-env 1.1.5\n","\u001b[2K    Uninstalling pytest-env-1.1.5:\n","\u001b[2K      Successfully uninstalled pytest-env-1.1.5\n","\u001b[2K  Attempting uninstall: minitorch\n","\u001b[2K    Found existing installation: minitorch 0.5\n","\u001b[2K    Uninstalling minitorch-0.5:\n","\u001b[2K      Successfully uninstalled minitorch-0.5\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [minitorch]\n","\u001b[1A\u001b[2KSuccessfully installed attrs-25.4.0 colorama-0.4.6 hypothesis-6.138.2 iniconfig-2.3.0 llvmlite-0.45.1 minitorch-0.5 numba-0.62.1 numpy-1.26.4 packaging-25.0 pluggy-1.6.0 pygments-2.19.2 pytest-8.4.1 pytest-env-1.1.5 sortedcontainers-2.4.0 typing-extensions-4.15.0\n"]}]},{"cell_type":"markdown","source":["# Run tests"],"metadata":{"id":"qufLzTGmzs1K"}},{"cell_type":"code","source":["!cd $DIR; python3.11 -m pytest -m task3_3 -v"],"metadata":{"id":"ySEAy1N7W1nF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763416057607,"user_tz":300,"elapsed":201870,"user":{"displayName":"Ying Yu Chen","userId":"03623175098010197464"}},"outputId":"5656a28b-18d9-4551-d4dc-acd727387c24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.11.14, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3.11\n","cachedir: .pytest_cache\n","hypothesis profile 'default'\n","rootdir: /content/module-3-chenyingyu-main\n","configfile: pyproject.toml\n","plugins: hypothesis-6.138.2, env-1.1.5\n","collected 117 items / 60 deselected / 57 selected                              \u001b[0m\n","\n","tests/test_tensor_general.py::test_create[cuda] \u001b[32mPASSED\u001b[0m\u001b[32m                   [  1%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn0] \u001b[32mPASSED\u001b[0m\u001b[32m             [  3%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn1] \u001b[32mPASSED\u001b[0m\u001b[33m             [  5%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn2] \u001b[32mPASSED\u001b[0m\u001b[33m             [  7%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn3] \u001b[32mPASSED\u001b[0m\u001b[33m             [  8%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn4] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 10%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn5] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 12%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn6] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 14%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn7] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 15%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn8] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 17%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn9] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 19%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn10] \u001b[32mPASSED\u001b[0m\u001b[33m            [ 21%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn11] \u001b[32mPASSED\u001b[0m\u001b[33m            [ 22%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn12] \u001b[32mPASSED\u001b[0m\u001b[33m            [ 24%]\u001b[0m\n","tests/test_tensor_general.py::test_one_args[cuda-fn13] \u001b[32mPASSED\u001b[0m\u001b[33m            [ 26%]\u001b[0m\n","tests/test_tensor_general.py::test_two_args[cuda-fn0] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 28%]\u001b[0m\n","tests/test_tensor_general.py::test_two_args[cuda-fn1] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 29%]\u001b[0m\n","tests/test_tensor_general.py::test_two_args[cuda-fn2] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 31%]\u001b[0m\n","tests/test_tensor_general.py::test_two_args[cuda-fn3] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 33%]\u001b[0m\n","tests/test_tensor_general.py::test_two_args[cuda-fn4] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 35%]\u001b[0m\n","tests/test_tensor_general.py::test_two_args[cuda-fn5] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 36%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn0] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 38%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn1] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 40%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn2] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 42%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn3] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 43%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn4] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 45%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn5] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 47%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn6] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 49%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn7] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 50%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn8] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 52%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn9] \u001b[32mPASSED\u001b[0m\u001b[33m       [ 54%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn10] \u001b[32mPASSED\u001b[0m\u001b[33m      [ 56%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn11] \u001b[32mPASSED\u001b[0m\u001b[33m      [ 57%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn12] \u001b[32mPASSED\u001b[0m\u001b[33m      [ 59%]\u001b[0m\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn13] \u001b[32mPASSED\u001b[0m\u001b[33m      [ 61%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad[cuda-fn0] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 63%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad[cuda-fn1] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 64%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad[cuda-fn2] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 66%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad[cuda-fn3] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 68%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad[cuda-fn4] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 70%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad[cuda-fn5] \u001b[32mPASSED\u001b[0m\u001b[33m             [ 71%]\u001b[0m\n","tests/test_tensor_general.py::test_reduce[cuda-fn0] \u001b[32mPASSED\u001b[0m\u001b[33m               [ 73%]\u001b[0m\n","tests/test_tensor_general.py::test_reduce[cuda-fn1] \u001b[32mPASSED\u001b[0m\u001b[33m               [ 75%]\u001b[0m\n","tests/test_tensor_general.py::test_reduce[cuda-fn2] \u001b[32mPASSED\u001b[0m\u001b[33m               [ 77%]\u001b[0m\n","tests/test_tensor_general.py::test_sum_practice \u001b[32mPASSED\u001b[0m\u001b[33m                   [ 78%]\u001b[0m\n","tests/test_tensor_general.py::test_sum_practice2 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 80%]\u001b[0m\n","tests/test_tensor_general.py::test_sum_practice3 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 82%]\u001b[0m\n","tests/test_tensor_general.py::test_sum_practice4 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 84%]\u001b[0m\n","tests/test_tensor_general.py::test_sum_practice5 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 85%]\u001b[0m\n","tests/test_tensor_general.py::test_sum_practice_other_dims \u001b[32mPASSED\u001b[0m\u001b[33m        [ 87%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn0] \u001b[32mPASSED\u001b[0m\u001b[33m   [ 89%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn1] \u001b[32mPASSED\u001b[0m\u001b[33m   [ 91%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn2] \u001b[32mPASSED\u001b[0m\u001b[33m   [ 92%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn3] \u001b[32mPASSED\u001b[0m\u001b[33m   [ 94%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn4] \u001b[32mPASSED\u001b[0m\u001b[33m   [ 96%]\u001b[0m\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn5] \u001b[32mPASSED\u001b[0m\u001b[33m   [ 98%]\u001b[0m\n","tests/test_tensor_general.py::test_permute[cuda] \u001b[32mPASSED\u001b[0m\u001b[33m                  [100%]\u001b[0m\n","\n","\u001b[33m=============================== warnings summary ===============================\u001b[0m\n","tests/test_tensor_general.py: 16 warnings\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py: 69 warnings\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py:938: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py: 13 warnings\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n","tests/test_tensor_general.py::test_sum_practice2\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn4]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 9 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn4]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn4]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 12 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_one_derivative[cuda-fn7]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 18 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_sum_practice_other_dims\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_two_grad_broadcast[cuda-fn4]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 27 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n","\u001b[33m========= \u001b[32m57 passed\u001b[0m, \u001b[33m\u001b[1m60 deselected\u001b[0m, \u001b[33m\u001b[1m109 warnings\u001b[0m\u001b[33m in 200.77s (0:03:20)\u001b[0m\u001b[33m ==========\u001b[0m\n"]}]},{"cell_type":"code","source":["!cd $DIR; python3.11 -m pytest -m task3_4 -v"],"metadata":{"id":"PGvP97HqmoQq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763416071376,"user_tz":300,"elapsed":13766,"user":{"displayName":"Ying Yu Chen","userId":"03623175098010197464"}},"outputId":"2960f46a-7cd7-4ba3-838d-3ea5309e63d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.11.14, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3.11\n","cachedir: .pytest_cache\n","hypothesis profile 'default'\n","rootdir: /content/module-3-chenyingyu-main\n","configfile: pyproject.toml\n","plugins: hypothesis-6.138.2, env-1.1.5\n","collected 117 items / 110 deselected / 7 selected                              \u001b[0m\n","\n","tests/test_tensor_general.py::test_mul_practice1 \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 14%]\u001b[0m\n","tests/test_tensor_general.py::test_mul_practice2 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 28%]\u001b[0m\n","tests/test_tensor_general.py::test_mul_practice3 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 42%]\u001b[0m\n","tests/test_tensor_general.py::test_mul_practice4 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 57%]\u001b[0m\n","tests/test_tensor_general.py::test_mul_practice5 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 71%]\u001b[0m\n","tests/test_tensor_general.py::test_mul_practice6 \u001b[32mPASSED\u001b[0m\u001b[33m                  [ 85%]\u001b[0m\n","tests/test_tensor_general.py::test_bmm[cuda] \u001b[32mPASSED\u001b[0m\u001b[33m                      [100%]\u001b[0m\n","\n","\u001b[33m=============================== warnings summary ===============================\u001b[0m\n","tests/test_tensor_general.py::test_mul_practice1\n","tests/test_tensor_general.py::test_mul_practice3\n","tests/test_tensor_general.py::test_mul_practice3\n","tests/test_tensor_general.py::test_bmm[cuda]\n","tests/test_tensor_general.py::test_bmm[cuda]\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py: 12 warnings\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py:938: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_mul_practice4\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 35 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_mul_practice4\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_mul_practice5\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 12 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 36 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 27 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 24 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 5 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","tests/test_tensor_general.py::test_bmm[cuda]\n","  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: \u001b[1mGrid size 48 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n","    warn(NumbaPerformanceWarning(msg))\n","\n","-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n","\u001b[33m=============== \u001b[32m7 passed\u001b[0m, \u001b[33m\u001b[1m110 deselected\u001b[0m, \u001b[33m\u001b[1m36 warnings\u001b[0m\u001b[33m in 12.65s\u001b[0m\u001b[33m ================\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# Run Training"],"metadata":{"id":"AISCSio8ryAG"}},{"cell_type":"code","source":["if False:\n","  import time\n","  # test if the training goes well\n","\n","  # Simple Dataset - GPU\n","  start = time.time()\n","  !cd $DIR; PYTHONPATH=/content/$DIR python3.11 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET simple --RATE 0.05\n","  gpu_time = time.time() - start\n","  print(f\"\\n=== GPU Total Time: {gpu_time:.2f}s ===\")\n","  print(f\"=== Time per Epoch: {gpu_time/500:.3f}s ===\")\n","\n","  # Simple Dataset - CPU\n","  start = time.time()\n","  !cd $DIR; PYTHONPATH=/content/$DIR python3.11 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET simple --RATE 0.05\n","  cpu_time = time.time() - start\n","  print(f\"\\n=== CPU Total Time: {cpu_time:.2f}s ===\")\n","  print(f\"=== Time per Epoch: {cpu_time/500:.3f}s ===\")"],"metadata":{"id":"M21R2NAYolKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if True:\n","  # train with three dataset on both cpu and gpu\n","  # training log after finished\n","  # summary with a graph\n","\n","  import time\n","\n","  # Results storage\n","  results = {\n","      'simple': {},\n","      'split': {},\n","      'xor': {}\n","  }\n","\n","  # Run all experiments\n","  for dataset in ['simple', 'split', 'xor']:\n","      print(f\"\\n{'#'*70}\")\n","      print(f\"# Dataset: {dataset.upper()}\")\n","      print(f\"{'#'*70}\\n\")\n","\n","      # GPU\n","      print(f\"Running on GPU...\")\n","      start = time.time()\n","      !cd $DIR; PYTHONPATH=/content/$DIR python3.11 project/run_fast_tensor.py \\\n","          --BACKEND gpu --HIDDEN 100 --DATASET {dataset} --RATE 0.05 2>&1 | grep -E \"(Epoch|correct)\"\n","      gpu_time = time.time() - start\n","      results[dataset]['gpu'] = gpu_time\n","      print(f\"GPU Time: {gpu_time:.2f}s ({gpu_time/500:.3f}s per epoch)\\n\")\n","\n","      # CPU\n","      print(f\"Running on CPU...\")\n","      start = time.time()\n","      !cd $DIR; PYTHONPATH=/content/$DIR python3.11 project/run_fast_tensor.py \\\n","          --BACKEND cpu --HIDDEN 100 --DATASET {dataset} --RATE 0.05 2>&1 | grep -E \"(Epoch|correct)\"\n","      cpu_time = time.time() - start\n","      results[dataset]['cpu'] = cpu_time\n","      print(f\"CPU Time: {cpu_time:.2f}s ({cpu_time/500:.3f}s per epoch)\\n\")\n","\n","      speedup = cpu_time / gpu_time\n","      print(f\"Speedup: {speedup:.2f}x\\n\")\n","\n","  # Print summary table\n","  print(\"\\n\" + \"=\"*70)\n","  print(\"SUMMARY\")\n","  print(\"=\"*70)\n","  print(f\"{'Dataset':<15} {'GPU Time':<15} {'CPU Time':<15} {'Speedup':<10}\")\n","  print(\"-\"*70)\n","  for dataset in ['simple', 'split', 'xor']:\n","      gpu = results[dataset]['gpu']\n","      cpu = results[dataset]['cpu']\n","      speedup = cpu / gpu\n","      print(f\"{dataset:<15} {gpu:>6.2f}s ({gpu/500:.3f}s)  {cpu:>6.2f}s ({cpu/500:.3f}s)  {speedup:>6.2f}x\")"],"metadata":{"id":"8ARAza9kUgeB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763418304875,"user_tz":300,"elapsed":2233482,"user":{"displayName":"Ying Yu Chen","userId":"03623175098010197464"}},"outputId":"177e95ef-1f56-4ef7-eccb-d733875c660a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","######################################################################\n","# Dataset: SIMPLE\n","######################################################################\n","\n","Running on GPU...\n","Epoch  0  loss  49.61079539828879 correct 396\n","Epoch  10  loss  21.593731660819888 correct 493\n","Epoch  20  loss  14.373737447747168 correct 492\n","Epoch  30  loss  10.79728634796506 correct 500\n","Epoch  40  loss  7.910825895035382 correct 498\n","Epoch  50  loss  8.5846880041248 correct 499\n","Epoch  60  loss  6.71990907937991 correct 499\n","Epoch  70  loss  6.571671323260893 correct 499\n","Epoch  80  loss  5.411215937945851 correct 500\n","Epoch  90  loss  4.057698089507355 correct 499\n","GPU Time: 292.55s (0.585s per epoch)\n","\n","Running on CPU...\n","Epoch  0  loss  53.97566261707796 correct 442\n","Epoch  10  loss  23.929828202598042 correct 478\n","Epoch  20  loss  11.959024773847704 correct 485\n","Epoch  30  loss  10.62618445549168 correct 496\n","Epoch  40  loss  12.502628398571142 correct 498\n","Epoch  50  loss  10.024342754324962 correct 489\n","Epoch  60  loss  9.680128177740318 correct 500\n","Epoch  70  loss  6.424864280877654 correct 494\n","Epoch  80  loss  7.410002510182145 correct 500\n","Epoch  90  loss  6.264253574659935 correct 498\n","CPU Time: 455.25s (0.910s per epoch)\n","\n","Speedup: 1.56x\n","\n","\n","######################################################################\n","# Dataset: SPLIT\n","######################################################################\n","\n","Running on GPU...\n","Epoch  0  loss  65.22015771839145 correct 340\n","Epoch  10  loss  55.664612806448034 correct 435\n","Epoch  20  loss  42.501277236779686 correct 434\n","Epoch  30  loss  34.68019455982878 correct 473\n","Epoch  40  loss  29.104150116442188 correct 482\n","Epoch  50  loss  20.426862258589136 correct 488\n","Epoch  60  loss  20.227450550188728 correct 492\n","Epoch  70  loss  20.278016349765842 correct 485\n","Epoch  80  loss  18.733389648407773 correct 494\n","Epoch  90  loss  13.525796442002623 correct 487\n","GPU Time: 287.66s (0.575s per epoch)\n","\n","Running on CPU...\n","Epoch  0  loss  63.61156715262269 correct 292\n","Epoch  10  loss  58.5451244437953 correct 394\n","Epoch  20  loss  51.002574696200774 correct 402\n","Epoch  30  loss  41.23150384418122 correct 432\n","Epoch  40  loss  36.87336367860576 correct 463\n","Epoch  50  loss  32.81412068396939 correct 471\n","Epoch  60  loss  28.291426324075474 correct 474\n","Epoch  70  loss  25.62092362033153 correct 486\n","Epoch  80  loss  21.382001984333282 correct 481\n","Epoch  90  loss  18.512966885940806 correct 485\n","CPU Time: 454.32s (0.909s per epoch)\n","\n","Speedup: 1.58x\n","\n","\n","######################################################################\n","# Dataset: XOR\n","######################################################################\n","\n","Running on GPU...\n","Epoch  0  loss  63.28198306038507 correct 329\n","Epoch  10  loss  48.418900491092856 correct 412\n","Epoch  20  loss  36.5055439360576 correct 422\n","Epoch  30  loss  35.83479293623333 correct 437\n","Epoch  40  loss  30.630583088809527 correct 437\n","Epoch  50  loss  31.889644189673696 correct 444\n","Epoch  60  loss  27.394360195018493 correct 441\n","Epoch  70  loss  24.560057623261695 correct 453\n","Epoch  80  loss  25.62408485215578 correct 461\n","Epoch  90  loss  24.70279812424399 correct 457\n","GPU Time: 288.24s (0.576s per epoch)\n","\n","Running on CPU...\n","Epoch  0  loss  60.76999649195341 correct 401\n","Epoch  10  loss  41.71278230953511 correct 443\n","Epoch  20  loss  32.86429441203653 correct 451\n","Epoch  30  loss  30.718845498526836 correct 452\n","Epoch  40  loss  28.78606896397327 correct 457\n","Epoch  50  loss  28.27017554227548 correct 461\n","Epoch  60  loss  23.300035150786705 correct 461\n","Epoch  70  loss  21.9336269663188 correct 464\n","Epoch  80  loss  20.081090388877815 correct 468\n","Epoch  90  loss  21.479034998142343 correct 470\n","CPU Time: 455.52s (0.911s per epoch)\n","\n","Speedup: 1.58x\n","\n","\n","======================================================================\n","SUMMARY\n","======================================================================\n","Dataset         GPU Time        CPU Time        Speedup   \n","----------------------------------------------------------------------\n","simple          292.55s (0.585s)  455.25s (0.910s)    1.56x\n","split           287.66s (0.575s)  454.32s (0.909s)    1.58x\n","xor             288.24s (0.576s)  455.52s (0.911s)    1.58x\n"]}]}]}